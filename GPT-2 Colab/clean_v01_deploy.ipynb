{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clean_v01_deploy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"vxoxhCqZn9O6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625575336927,"user_tz":-180,"elapsed":7357,"user":{"displayName":"erion","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWvcl2ald5nvmN_5SKA9F_ggwhh6OU3utLWLWv8Q=s64","userId":"15007589009372845537"}},"outputId":"200f56f6-286f-4393-cf58-352156e55a59"},"source":["!pip install -q transformers "],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.5MB 17.9MB/s \n","\u001b[K     |████████████████████████████████| 901kB 40.2MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 35.6MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"awg9x1jHoIhG","executionInfo":{"status":"ok","timestamp":1625575343973,"user_tz":-180,"elapsed":4321,"user":{"displayName":"erion","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWvcl2ald5nvmN_5SKA9F_ggwhh6OU3utLWLWv8Q=s64","userId":"15007589009372845537"}}},"source":["from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWNCOu-dndkD","executionInfo":{"status":"ok","timestamp":1625575343976,"user_tz":-180,"elapsed":16,"user":{"displayName":"erion","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWvcl2ald5nvmN_5SKA9F_ggwhh6OU3utLWLWv8Q=s64","userId":"15007589009372845537"}}},"source":["import os\n","from google.colab import drive\n","import torch\n","import random\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEbsOj5xngzO","outputId":"b7ce45ba-2cc5-44c0-f84b-25752ccdb1d5"},"source":["gdrive_dir = '/content/gdrive/'\n","drive.mount(gdrive_dir, force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w_AfaiXxqKkL"},"source":["dir2 = \"/content/gdrive/MyDrive/Colab Notebooks/v2/model_save\"\n","dir3 = \"/content/gdrive/MyDrive/Colab Notebooks/v2/model_save/config.json\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B878HONVnrwD"},"source":["#Load a trained model and vocabulary that you have fine-tuned\n","config = GPT2Config.from_json_file(dir3)\n","model = GPT2LMHeadModel.from_pretrained(dir2)\n","tokenizer = GPT2Tokenizer.from_pretrained(dir2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bqUpKcco5Ns"},"source":["# cleaning the occupied cuda memory\n","torch.cuda.empty_cache()\n","\n","# Tell pytorch to run this model on the GPU \n","# if not available then run on cpu \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#model.cuda()\n","\n","#  This step is optional but it wiil enable reproducible runs\n","seed_val = 0\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnHjiOj5qXLR"},"source":["model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pl4MyF3tPI2-"},"source":["from transformers import pipeline\n","\n","# Named entity recognition pipeline, passing in a specific model and tokenizer\n","text_generator = pipeline('text-generation', tokenizer=tokenizer, model=model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_r4TUAxjvmmu"},"source":["input =\"T9216074 03/02/2020 Γιάννης Eurudike Παπάς\tKhatzekharistou\tΘεοτόκης Παγώνα Σπαθάρη\t19/03/1943 Χίος Κοζάνη-Πάτρα 12925/7 Υ.Α. Κοζάνη Χίος\"\n","question = \"Name Greek: \"\n","\n","prompt = input +\" --<input>--  --<question>-- \" +question"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MsgGGLbU77h","outputId":"70b22ebb-1a50-48d0-d54b-e94c7ae2c20e"},"source":["output = text_generator(prompt, return_full_text=False, max_length=200)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tvPma2iiXhIt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"36ec4433-4c16-4af3-852c-1a49e796c691"},"source":["output"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': ' --<answer>-- Γιάννης'}]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"NHqmqRngzvWr"},"source":[""],"execution_count":null,"outputs":[]}]}
